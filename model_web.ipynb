{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "# data 불러오기\n",
    "def load_data():\n",
    "    global df_main, df2\n",
    "    \n",
    "    df1 = pd.read_csv('./data/df.csv')\n",
    "    df2 = pd.read_csv(\"./data/weather.csv\")\n",
    "    \n",
    "    # 필요한 부분만 추출\n",
    "    df_main = df1[ ['ID','이름', '대분류','소분류', '평점', '투표횟수','실내/실외', '태깅'] ]\n",
    "\n",
    "    return df_main, df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countVec():\n",
    "    # CountVectorizer를 적용하기 위해 공백문자로 word 단위가 구분되는 문자열로 변환. \n",
    "    count_vect = CountVectorizer(min_df=0, ngram_range=(1, 2))\n",
    "    facility_mat = count_vect.fit_transform( df_main['태깅'] )\n",
    "    facility_sim = cosine_similarity(facility_mat, facility_mat)\n",
    "\n",
    "    # 유사도가 높은 순으로 정리된 facility_sim 객체의 비교 행 위치 인덱스 값\n",
    "    # 값이 높은 순으로 정렬된 비교 대상 행의 유사도 값이 아니라\n",
    "    # 비교 대상 행의 위치 인덱스임에 주의\n",
    "    facility_sim_sorted_ind = facility_sim.argsort()[:, ::-1]\n",
    "    \n",
    "    return facility_sim_sorted_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 평점을 가중 평점으로 변경하는 함수\n",
    "def weighted_vote_average(record):\n",
    "  C = df_main['평점'].mean()\n",
    "  m = df_main['투표횟수'].quantile(0.6)\n",
    "  \n",
    "  v = record['투표횟수']\n",
    "  R = record['평점']\n",
    "  # (예정)날씨 관련 수식을 추가 => 실내외 구분시 활용\n",
    "  return ( ( (v/(v+m)) * R ) + ( (m/(v+m)) * C ) ) *2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_data():\n",
    "    df_main['추천점수'] = df_main.apply(weighted_vote_average, axis=1)\n",
    "\n",
    "    # 새롭게 부여된 가중치 평점이 높은 순으로 상위 10개의 시설\n",
    "    df_head_1 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='미술관'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_2 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='박물관'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_3 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='공연장'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_4 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='전통문화'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_5 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='5.18운동'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_6 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='사찰/기독교'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_7 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='선비문화'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_8 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='문화유산'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_9 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='체험'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_10 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='공원'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_11 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='맛집'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_12 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='시장'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_13 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='스포츠'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "    df_head_14 = df_main[['이름','대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']][df_main['소분류']=='마을'].sort_values(\n",
    "        '추천점수', ascending=False).head(1)\n",
    "\n",
    "    result_df = pd.concat([df_head_1,df_head_2,df_head_3,df_head_4,df_head_5,df_head_6,df_head_7,df_head_8,df_head_9,df_head_10,df_head_11,df_head_12,df_head_13, df_head_14])\n",
    "    return result_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새롭게 정의된 평점 기준에 따라 기존 find_sim_experience 함수를 변경\n",
    "def find_sim_experience(df_main, sorted_ind, title_name, top_n=10, end_idx=10):\n",
    "  weight_data()\n",
    "  title_exp = df_main[df_main['이름'] == title_name]\n",
    "  title_index = title_exp.index.values\n",
    "\n",
    "  sim_index = sorted_ind[title_index, :top_n*3]\n",
    "  sim_index = sim_index.reshape(-1)\n",
    "\n",
    "  sim_index = sim_index[sim_index != title_index]\n",
    "\n",
    "  return df_main.iloc[sim_index].sort_values(\n",
    "    '추천점수', ascending=False)[:end_idx]\n",
    "\n",
    "# 우천시 추천리스트 10개 출력\n",
    "def find_sim_experience_rainy(df_main, sorted_ind, title_name, top_n=10):\n",
    "  weight_data()\n",
    "  title_exp = df_main[df_main['이름'] == title_name]\n",
    "  title_index = title_exp.index.values\n",
    "\n",
    "  sim_index = sorted_ind[title_index, :top_n*3]\n",
    "  sim_index = sim_index.reshape(-1)\n",
    "\n",
    "  sim_index = sim_index[sim_index != title_index]\n",
    "\n",
    "  return df_main.iloc[sim_index].sort_values(\n",
    "    '추천점수', ascending=False)[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_title(input_name):\n",
    "    facility_sim_sorted_ind = countVec()\n",
    "    \n",
    "    sim_exp = find_sim_experience(df_main, facility_sim_sorted_ind, input_name)\n",
    "    sim_exp_rainy = find_sim_experience_rainy(df_main, facility_sim_sorted_ind, input_name)\n",
    "    result_sunny = sim_exp[['이름', '대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']]\n",
    "    result_rain = sim_exp_rainy[['이름', '대분류', '소분류', '실내/실외', '평점', '투표횟수', '추천점수']]\n",
    "\n",
    "    return result_sunny, result_rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날씨기반 실내/외 판별 함수\n",
    "# temper = 온도 , humid = 습도 , rain = 1시간당 강수량\n",
    "\n",
    "def weather_choice(temper,humid,rain):\n",
    "  y = humid - ((-4.3 * temper) + 147)\n",
    "  if y >= 10:\n",
    "    temper = temper + (y/10)\n",
    "\n",
    "  if rain >= 5 or temper<=10 or temper>=30:\n",
    "    return '실내'\n",
    "  else:\n",
    "    return '실외'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8733d06c9a6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_sunny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'어나더키친'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-8733d06c9a6a>\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(input_name, weather)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mresult_sunny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_rain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# 날씨로 실내/실외 필터링\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-151e8d0b36d5>\u001b[0m in \u001b[0;36minput_title\u001b[1;34m(input_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minput_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfacility_sim_sorted_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountVec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msim_exp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_sim_experience\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_main\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfacility_sim_sorted_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msim_exp_rainy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_sim_experience_rainy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_main\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfacility_sim_sorted_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-f3f8a9c228ae>\u001b[0m in \u001b[0;36mcountVec\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# CountVectorizer를 적용하기 위해 공백문자로 word 단위가 구분되는 문자열로 변환.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcount_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfacility_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdf_main\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'태깅'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mfacility_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfacility_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfacility_mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1203\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dacon\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[0;32m    218\u001b[0m                              \"unicode string.\")\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "def run_model(input_name, weather=0):\n",
    "    # weather = 맑음 : 0 (default) / 비 : 1    \n",
    "    \n",
    "    _, df2 = load_data()\n",
    "    result_sunny, result_rain = input_title(input_name)\n",
    "    \n",
    "    # 날씨로 실내/실외 필터링\n",
    "    \n",
    "    temper = df2.loc[weather][0:][0] # 온도\n",
    "    humid = df2.loc[weather][0:][1]  # 습도\n",
    "    rain = df2.loc[weather][0:][2]   # 강수량\n",
    "        \n",
    "        # 비 -> 실내만 추천\n",
    "    if weather_choice(temper, humid, rain) == \"실내\":\n",
    "        print(result_rain[result_rain['실내/실외'] == \"실내\"][:10])\n",
    "        \n",
    "        # 맑음 -> 실내/외 모두 추천\n",
    "    else :\n",
    "        print(result_sunny)\n",
    "\n",
    "run_model('어나더키친')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5327134b4d9c90ef246a62c4b08a4aaf90b0cea1e5a2b066b88c3413ddfa8b04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('dacon': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
